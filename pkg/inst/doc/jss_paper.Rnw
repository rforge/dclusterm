%Sweave("jss_paper.Rnw", encoding = "UTF-8", keep.source = FALSE); system("pdflatex jss_paper.tex"); system("bibtex jss_paper"); system("pdflatex jss_paper.tex"); system("pdflatex jss_paper.tex")
%system("pdflatex jss_paper.tex")
%system("bibtex jss_paper")

\documentclass[article]{jss}

\usepackage{thumbpdf}
\usepackage{amssymb}
%% need no \usepackage{Sweave.sty}

\usepackage{showlabels}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Virgilio G\'omez-Rubio\\Universidad de Castilla-La Mancha
\And Paula Moraga-Serrano\\London School of Hygiene\\ \& Tropical Medicine
\AND John Molitor\\Oregon State University
\And Barry Rowlingson\\Lancaster University
%Achim Zeileis\\Universit\"at Innsbruck \And 
%        Second Author\\Plus Affiliation}
}

%\title{Extending the \pkg{R-INLA} Package for Spatial Statistics}
%\title{Some Spatial Statistical Extensions to \pkg{R-INLA}}
\title{\pkg{DClusterm}: Model-based Detection of Disease Clusters}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Virgilio G\'omez-Rubio et al.}%, Paula Moraga-Serrano}
\Plaintitle{DClusterm: Model-based detection of disease clusters}
%\Shorttitle{} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
The detection of regions with unusual high risk plays an important role in
disease mapping and the analysis of Public Health data. In particular, the
detection of groups of areas (i.e., clusters) where the risk is significantly 
high is often conducted by Public Health authorities.

Many methods have been proposed for the detection of disease clusters, most of
them based on moving windows, such as, Kulldorff's Spatial Scan Statistics
(SSS).  Here we describe a model-based approach for the detection of disease
clusters implemented in the \pkg{DClusterm} package. Our model-based
approach is based on representing a large number of possible clusters by
dummy variables and then fitting many genralized linear models to the data wherethese covariates are included one at a time. Cluster detection is done by 
performing a variable or model selection among all fitted models using
different criteria.

Because of our model-based approach, cluster detection can be performed using
different types of likelihoods anf latent effects. We cover the detection of
spatial and spatio-temporal clusters, as well as how to account for covariates,
deal with zero-inflated datasets and overdispersion in the data.

}


\Keywords{disease cluster, spatial statistics, \proglang{R}}
\Plainkeywords{disease cluster, spatial statistics, R}

\Address{
Virgilio G\'omez-Rubio\\
Department of Mathematics\\
School of Industrial Engineering\\
University of Castilla-La Mancha\\
02071 Albacete, Spain\\
E-mail: \email{virgilio.gomez@uclm.es}\\
URL: \url{http://www.uclm.es/profesorado/vgomez}\\
 \\
Paula Moraga-Serrano\\
London School of Hygiene \& Tropical Medicine\\
Keppel Street\\
WC1E 7HT London, United Kingdom\\
E-mail: \email{paula.moraga-serrano@lshtm.ac.uk}\\
URL: \url{http://www.lshtm.ac.uk/aboutus/people/moraga-serrano.paula}\\
\\
John Molitor\\
College of Public Health and Human Sciences\\
Oregon State University\\
Corvallis, Oregon 97331, United States\\
E-mail: \email{John.Molitor@oregonstate.edu}\\
URL: \url{http://health.oregonstate.edu/people/molitor-john}\\
\\
Barry Rowlingson\\
Lancaster Medical School\\
Furness Building\\
Lancaster University\\
Bailrigg, Lancaster LA1 4YG, United Kingdom\\
E-mail: \email{b.rowlingson@lancaster.ac.uk}\\
URL: \url{http://www.lancaster.ac.uk/fhm/about-us/people/barry-rowlingson}\\
}






\begin{document}

\maketitle

\section{Introduction}

The analysis of epidemiological data at small area level often involves
accounting for possible risks factors and other important covariates using
different types of regression models.  However, it is not uncommon that after a
number of covariates have been accounted for, residuals show a spatial
distribution that defines some groups of areas with unusual high
epidemiological risk. Hence, in many ocassions it is not clear whether all
spatial risk factors have been included in our model.

Public health data are often aggregated over small administrative areas
becasue of confidentiality issues, but it is not uncommon that individual data 
are available. Generalised Linear Models \citep[GLM,][]{} are a
common framework for disease mapping to model aggregated and individual data.
GLMs not only model Poisson or Binomial responses, but they can also link the
outocome to a linear predictor on the covariates (and, possibly, other effects).
However, until recently, it was not clear how to use GLMs to detect clusters
of disease, i.e., a group of contiguous areas with significant high risk.

In order to detect disease clusters, probably the most widely used method is
the one proposed by \citet{Kulldorff:1997}. This is called the Spatial Scan
Statistic and it will find the most likely cluster. Significance is assessed
via a Monte Carlo test using a test statistic based on a likelihood ratio test
for the following
hypotheses:

$$
\begin{array}{cc}
H_0: & \theta_z=\theta_{\overline{z}}\\
H_1: & \theta_z>\theta_{\overline{z}}\\
\end{array}
$$

Here, $z$ represents a cluster (i.e., a set of contiguous areas), $\theta_z$
the relative risk in the cluster and $\theta_{\overline{z}}$ the relative risk
outside the cluster. Many different clusters are tested in turn. The most
likely cluster is the one with the highest value of the test statistic. Then a
Monte Carlo test is used to compute the p-value of the most likely cluster.

In this paper we will summarise the work by several authors that have established a link
between GLMs and SSS, so that the detectiopn of disease clusters is approached from a
regression point of view. As described later, this will involved fitting many different
GLMs for which dummy variables that represent possible clusters are included one at a time.
Cluster detection is based on selecting a number of dummy cluster variables using variable
selection methods. Furthermore, we will describe how these methods have been implemented
in the \pkg{DClusterm} package for the \proglang{R} software.


This paper is organised as follows. Section \ref{sec:GLM} will introduce the link
between GLM and SSS. Next, in Section \ref{sec:spacetime} we describe how to extend 
these ideas to dectect clusters in space and time. The detection of disease clusters
for zero-inflated data is discussed in Section \ref{sec:zeroinfl}. Section \ref{sec:mixed}
shows how to include random effects in the detection of disease clusters. 
A multivariate approach for the detection of disease clusters of two diseases has
been included in Section \ref{sec:bivar}. Finally, a discussion and some final remarks
are provided in Section \ref{sec:disc}.



\section{Generalised linear models for cluster detection}
\label{sec:GLM}


\citet{Jung:2009,ZhangLinCSDA:2009} provide a explicit link between GLMs and
the SSS, and show that the test statistic for a given cluster is equivalent to
fitting a Generalised Linear Model using a cluster variable as a predictor.
This cluster variable is a dummy variable which is 1 for the areas in the
cluster and 0 for the areas outside the cluster.

Firstly, given that we are using GLM's we could include covariates in the 
model. For example, for a Poisson model with expected counts $E_i$ 
we could have:

$$
O_i \sim Po(E_i \theta_i)
$$

$$
\log(\theta_i) = \log(E_i) + \alpha + \beta x_i 
$$
\noindent
Fitting this model will provide estimates $\hat\alpha$ and $\hat\beta$.
This will account for the (spatial) effects of the covariates. In order
to include the cluster variable the effects of the covariates will be keep
fixed. Hence, the clusters covariates will be used in a model with fixed
coefficients for the covariates:

$$
\log(\theta_i) = \log(E_i) + \hat\alpha + \hat\beta x_i + \gamma_j CLUSTER_j
$$
\noindent
This means that the offset now is $\log(E_i)+\hat\alpha+\hat\beta x_i$.
$\gamma_j$ is a measure of the difference of the risk in the cluster. We
are only interested in clusters whose coefficient is higher than 0 (i.e.,
increased risk), hence those with a significant negative coefficient will
be ignored.

Testing different clusters will produce many different cluster covariates.
We can use model selection techniques to select the most important cluster in 
the area.  In particular, the log-likelihood can be used to 
compare the model with the cluster variable to the null model (i.e., the
one with the covariates only). Note that we are interested in clusters with 
a high risk and, because of that, we are only interested in clustes whose associated
coefficient is significantly higher than zero.

Regarding the effect of the covariates, it is possible to perform a cluster
dection without considering covariates in the model. Then a cluster detection
accouting for the covariates will likely provide a different number of
clusters. By comparing the clusters detected in both cases we will be able to
find what clusters are linked to underlying risk factors included in the model
and what clusters remain unexplained by the covariates. In the examples that we
included in this paper we will always consider both scenarios to better
understand how cluster detection works with these methods.


\citet{BilanciaDemarinis:2014,GomezRubioetal:2015} describe a similar approach
to the detection of disease cluster using Bayesian hierarchical models. The
Integrated Nested Laplace Approximation is used in both cases for model fitting
as it provides computational benefits over other computationally expensive
methods, such as Markov Chain Monte Carlo.


%NY8 Example

%\input{NY.tex}

\subsection{Leukemia in upstate New York}

The \texttt{NY8} dataset is avaialble in package \texttt{DClusterm} and it
provides cases of leukemia in different census tracts in upstate New York.
This data set has been analysed by several authors
\citep{Walletetal:1992,WallerGotway:2004}.  The location of leukemia is thought
to be linked to the use of Trichloroethene (TCE) by several companies in the
area. Figure~\ref{fig:NYmap} shows the Standardised Mortality Ratios of the
census tracts and the locations of the industries using TCE.

In order to measure exposure, the inverse of the distance to the nearest TCE
site has been used (PEXPOSURE). In addition, two other socioeconomic covariates
have been used: the percentage of people aged 65 or more (PCTAGE65P) and the
percentage of people who own their home (PCTOWNHOME).

This dataset is included in package \pkg{DClusterm} as \code{NY8}. Hence, our first
action is to load some required packages and the dataset itself.

<<results = hide>>=
library(DClusterm)
library(snowfall)
library(xts)

data(NY8)
@

A number of cases could not be linked to their actual location and they were distributed
uniformly over the study are, making the counts real numbers instead of integers. We have
rounded these values as we intend to use a Poisson likelihood for the analysis. Furthermore,
expected counts are computed using the overall incidence ratio (total number of cases divided
by the total population). Age-sex standarisation is not possible in this case as this information
is not available in our dataset. 

<<results = hide>>=
NY8$Observed <- round(NY8$Cases)

NY8$Expected  <- NY8$POP8 * sum(NY8$Observed) / sum(NY8$POP8)

NY8$SMR <- NY8$Observed/NY8$Expected

NY8$x <- coordinates(NY8)[, 1]
NY8$y <- coordinates(NY8)[, 2]
@

Finally, a \code{STFDF} object is created to store all the data. Functions in \pkg{DClusterm}
will take object for space-time data as defined in package \pkg{spacetime}. Note that in this
case we do not have a truly space-time dataset.

<<results = hide>>=
NY8st <- STFDF(as(NY8, "SpatialPolygons"), xts(1, as.Date("1972-01-01")), NY8@data, 
  endTime = as.POSIXct(strptime(c("1972-01-01"), "%Y-%m-%d"), tz = "GMT"))
@


\begin{figure}[h]
<<fig=TRUE, echo=FALSE>>=
library(RColorBrewer)

#Save plots
p1 <- spplot(NY8, "SMR", cuts = 8, col.regions = brewer.pal(9, "Oranges"),
   main = "Standardised Mortality Ratio")
p2 <- spplot(NY8, "PCTOWNHOME", cuts = 8, col.regions = brewer.pal(9, "Blues"),
   main = "PCTOWNHOME")
p3 <- spplot(NY8, "PCTAGE65P", cuts = 8, col.regions = brewer.pal(9, "Greens"),
   main = "PCTAGE65P")
p4 <- spplot(NY8, "PEXPOSURE", cuts = 8, col.regions = rev(brewer.pal(9, "Reds")),
   main = "PEXPOSURE")

#Display plots
print(p1, position = c(0, 0.5, 0.5, 1), more = TRUE)
print(p2, position = c(0.5, 0.5, 1, 1), more = TRUE)
print(p3, position = c(0, 0, 0.5, 0.5), more = TRUE)
print(p4, position = c(0.5, 0, 1, 0.5))

@
\caption{**INCLUDE TCE LOCATIONS** SMR and covariates of the incidence of Leukemia in upstate New York dataset.}
\label{fig:NYmap}
\end{figure}
\subsection{Cluster detection}


\subsubsection{Cluster detection with no covariates}

First of all, a model with no covariates will be fitted and used as a baseline
for model fitting. For example, other models can be compared to this one (for
exaple, using the AIC or the log--likelihood) to assess whether they provide a
better fit. 

<<results=hide>>=
ny.m0 <- glm(Observed ~ offset(log(Expected)) + 1, family = "poisson", data = NY8)
@

Cluster detection will use the previous model and new cluster dummy variables
will be included, one at a time, to test for a large number of clusters.

Function \code{DetectClustersModel()} will take the baseline model (using
argument \code{model0}), create the cluster dummy variables and test them in
turn. Then, those clusters with a highest significance will be reported.

Argument \code{thegrid} will take a 2-column \code{data.frame} (with names
\code{x} and {y}) with the centres of possible clusters. If the grid of cluster
centres is not defined, then a rectagular grid is used with a distance between
adjacent points defined by argument \code{step}.  Dummy cluster variables are
created around these points are created by adding areas to the cluster until a
certain percentaje of the population has been reached (defined by argument
\code{fractpop}) or until a certain distance about the centre (defined by
argument \code{radius}). When testing for significant cluster variables, 
argument \code{alpha} defines the significance level.

\code{DetectClustersModel()} can detect spatial and spatio-temporal clusters,
that is why its first argument is a space-time object. The type of 
clusters that are investigated is defined by argument \code{typeCluster}.
In the example we have used \code{typeCluster = "S"}.

Other options include the number of CPUs to be used to test for clusters in
parallel (argument \code{numCPUS}) and the number of replicates for Monte Carlo
tests (argument \code{R}) if cluster assessment is done by simulation. By
default, Monte Carlo tests are not used.

In the following example, to reduce the computational burden, we have only
looked for clusters around 5 areas (whose rows in \code{NY8} are defined in
variable \code{idxcl}). In a real application we advice the use of all
locations (area centroids or actual locations of individual data).

<<results=hide>>=
idxcl <- c(120, 12, 89, 139, 146)
cl0 <- DetectClustersModel(NY8st, thegrid = as.data.frame(NY8)[idxcl, c("x", "y")], 
   fractpop = .15, alpha = 0.05, radius = Inf, step = NULL,
   typeCluster = "S", R = NULL, numCPUS = 4, model0 = ny.m0)
@


Below is a summary of the clusters detected. Dates can be ignored as this is a
purely spatial cluster. In the case of spatio-temporal clusters, the dates
shown define the temporal range of the cluster.  Values \code{x} and \code{y}
defined the cluster centre, \code{size} is the number of areas (or individuals)
in the cluster, \code{statistic} represents the point estimate of the
associated cluster coefficient Also, note that only clusters with a lower
\code{pvalue} than argument \code{alpha} are returned.  \code{cluster}
indicates whether the cluster is a significant one. Finally, note how detected
cluster are order by increasing value of \code{pvalue}, so that most 
significant clusters are reported first.

<<>>=   
cl0
@

The centre of the clusters detected are shown in Figure~\ref{fig:NYcl}.
Because of the lack of adjustment for covariates these clusters show regions of
high risk based on the raw data (observed and expected counts) alone.

%\begin{figure}[h!]
%\centering
<<eval = FALSE, echo=FALSE, fig=TRUE>>=
plot(NY8)
points(cl0[,1:2], pch=19, col="red")
@
%\caption{Clusters detected when no covariates are included in the model.}
%\label{fig:NYcl0}
%\end{figure}

\subsubsection{Cluster detection after adjusting for covariates}

Similarly, clusters can be detected after adjusting for significant risk
factors. First of all, we will fit a Poisson regression with the 3 covariates
mentioned earlier. As it can be seen, all three are significant:

<<>>=
ny.m1 <- glm(Observed ~ offset(log(Expected)) + PCTOWNHOME + PCTAGE65P + PEXPOSURE,
  family = "poisson", data = NY8)
summary(ny.m1)
@

As the three covariates are significant, the expected number of cases will be
different now and the detected clusters may be different in this case.  Cluster
detection is performed as in the previous example, but now we use the model
that adjusts for covariates instead:

<<results=hide>>=
cl1<-DetectClustersModel(NY8st, 
  thegrid = as.data.frame(NY8)[idxcl, c("x", "y")], 
  fractpop = .15, alpha = .05,
  typeCluster = "S", R = NULL, numCPUS = 4, model0 = ny.m1)
@

<<>>=
cl1
@

Figure~\ref{fig:NYcl} shows the clusters detected after adjusting for
covariates.  Compared to the example with no covariate adjustment, one custer
has dissappeared. Hence, that cluster has been explained by the effect of the
covariates. Another cluster is a bit smaller in size, which means that
covariate only explain a small part of it. The most significant cluster remains
the same. In all cases, cluster significance has been reduced by the effect of
the covariates.


\begin{figure}[!h]
\centering
<<echo=FALSE, fig=TRUE, width = 10, height = 5>>=
par(mfrow = c(1,2))

#No covariates
plot(NY8)
points(cl0[,1:2], pch=19, col="red")

#With covariates
plot(NY8)
points(cl1[,1:2], pch=19, col="red")
@
\caption{Clusters detected with no covariate adjustment (left) and after adjusting for 
  covariates (right).}
\label{fig:NYcl}
\end{figure}



\section{Spatio-temporal clusters}
\label{sec:spacetime}

%\input{NM.tex}

\citet{Jung:2009} discusses how to extend model-based approaches for the
detection of spatial disease clusters to space and time. 
\citet{GomezRubioetal:2015} propose the following model:

\begin{equation} 
\log(\mu_{i,t}) =  \log(E_{i,t}) + \gamma_j c^{(j)}
\label{eq:stcluster}
\end{equation}
\noindent
\noindent
where $\mu_{i,t}$ is the mean of area $i$ at time $t$ and $c^{(j)}$
a cluster dummy variable for cluster $j$. 

Note how now data are indexed according to space and time. Dummy cluster
variables are defined as in the spatial case, by considering areas in the
cluster according to their distance to the cluster centre, for data within 
a particular time period.  When defining a temporal cluster, areas are
aggregated using all possible temporal windows up to a predefined temporal 
range.


\subsection{Brain cancer in New Mexico}

The \code{brainNM} dataset (included in \pkg{DClusterm}) contains yearly cases
of brain cancer in New Mexico from 1973 to 1991 (inclusive) in a
\pkg{spacetime} object. The data set has been taken from the SatScan website
and the area boundaries from the U.S.  Census Bureau. In addition, the location
of Los Alamos National Laboratory (LANL) has been included (from the Wikipedia).
Inverse distance to this site can be used to test for increased risk in the
areas around the Laboratory as no other covariates are available. 

<<echo = FALSE, eval = FALSE>>=
library(DClusterm)
#debug(DetectClustersModel)
#debug(glmAndZIP.iscluster)
#debug(CalcStatsAllClusters)
library(snowfall)
@

<<>>=
data(brainNM)
@

Expected counts have been obtained using age and sex standardisation over the
whole period of time. Hence, yearly differences are likely to be seen when
plotting the data. Standardised Mortality Ratios have been plotted in
Figure~\ref{fig:NMSMR}.

\begin{figure}[!h]
\centering
<<echo=FALSE, fig=TRUE>>=
print(stplot(brainst[, , "SMR"], cuts = 8, 
  col.regions = brewer.pal(9, "Oranges")))
@
\caption{Standardised Mortality Ratios of brain cancer in New Mexico.}
\label{fig:NMSMR}
\end{figure}



\subsection{Cluster detection}

\subsubsection{Cluster detection with no covariates}

Similarly as in the purely spatial case, a Poisson regression with no 
covariates will be fitted first:

<<>>=
nm.m0 <- glm(Observed ~ offset(log(Expected)) + 1, family = "poisson", 
  data = brainst)
summary(nm.m0)
@

Before proceding with disease cluster detection, we have extracted the
centroids of the counties in New Mexico by using function \code{coordinates()}
on the \code{sp} slot in the \code{STIDF} object that stores the data.


<<results=hide>>=
NM.coords <- coordinates(brainst@sp)
@

Cluster detection with function \code{DetectClustersModel()} takes
now arguments \code{minDateUser} and \code{maxDateUser} to define
the minimum and maximum times that are considered when looking for
clusters. \code{typeCluster = "ST"} is used to look for spatio-temporal
clusters. **ANYTHING ELSE ABOUT HOW S-T CLUSTERS ARE DEFINED?**

** FIXME: Use complete time periord of data for cluster detection

<<results=hide>>=
cl0<-DetectClustersModel(brainst, NM.coords,
  minDateUser = "1985-01-01", maxDateUser = "1989-01-01",
  fractpop = .15, alpha = 0.05, typeCluster = "ST", R = NULL, 
  numCPUS = 4, model0 = nm.m0)
@

<<>>= 
nrow(cl0)
cl0[1:5,]
@

\subsubsection{Cluster detection after adjusting for covariates}

In this case, we will use the inverse of the distance to LANL as a covariate as
no other information about the areas is available. Distances have been computed
using function \code{spDistsN1} Given that coordinates are expressed in
longitude and latitude  great circle distances are used.

<<>>=
dst <- spDistsN1(pts = NM.coords, pt = losalamos, longlat = TRUE)
@

Distances need to be put together in a way that values are available for all time periods.
In this case, given that distances do not change over time, a vector is creaeted by repeating
the vector of distances as many times as time slots (years) we have in the dataset.

<<>>=
nyears <- length(unique(brainst$Year))
brainst$IDLANL <- rep(1/dst, nyears)
@

With all this data we are now able to fit a baseline model.

<<>>=
nm.m1 <- glm(Observed ~ offset(log(Expected)) + IDLANL,
   family = "poisson", data = brainst)
summary(nm.m1)
@

Note how now the included covariate is not significant. For illustrative
purposes, we will still keep the covariate in our model for the cluster
detection. However, non-significant covariates will have a tiny impact on the
clusters detected as they will not produce a change in the expected number of
cases.

** FIXME: Use complete time periord of data for cluster detection

<<results=hide>>=
cl1 <- DetectClustersModel(brainst, NM.coords, fractpop = 0.15, 
   alpha = 0.05, minDateUser = "1985-01-01", maxDateUser = "1989-01-01",
   typeCluster = "ST", R = NULL, numCPUS = 4, model0 = nm.m1)
@

The number of clusters detected in this case is \Sexpr{nrow(cl1)}, the same
as in the example with no covariates (**CHECK**). By inspecting the five most
significant clusters we can observe that they are very similar to the ones detected
before:

<<>>=
cl1[1:5,]
@

In order to exploit the output from \code{DetectClustersModel()}, function \code{get.stclusters()}
will take the data and this output to return a list with the indices of the areas in the cluster.
The next example shows how to add a new variable to \code{brainst} with the space-time regions
in the most significant cluster, which is displayed in Figure~\ref{fig:NMcluster}.

<<>>=
stcl <- get.stclusters(brainst, cl0)
brainst$CLUSTER <- 0
brainst$CLUSTER[ stcl[[1]] ] <- 1
@

\begin{figure}[!h]
\centering
<<echo = FALSE, fig=TRUE>>=
print(stplot(brainst[, , "CLUSTER"], at = c(0, 0.5, 1.5), 
  col.regions = c("white", "gray")))
@
\caption{Spatio-temporal cluster of brain cancer detected in New Mexico.}
\label{fig:NMcluster}
\end{figure}


\section{Zero-inflated models for cluster detection}
\label{sec:zeroinfl}

The analysis of rare diseases often involves datasets where there are many
areas with zero counts, leading to zero-inflated data. In this situation the
Poisson or Binomial likelihoods may not be suitable to fit a model and other
distributions for the data should be used.  \citet{RD:2010} discuss this issue
and they have extended model-based cluster detection methods to account for
zero-inflation. 

Four count data, a zero-inflated Poisson could be used. In this case,  observed
number of cases come from a mixture distribution:

$$
Pr(O_i=n_i)=
\left\{
\begin{array}{ll}
\pi_i+(1-\pi_i)Po(0|\theta_iE_i) & n_i=0\\
(1-\pi_i)Po(n_i|\theta_iE_i) & n_i=1,2,\ldots\\
\end{array}
\right.
$$
\noindent
Relative risk $\theta_i$ can be modelled using a log-linear model to depend on
some relevant risk factors. Also, it is common that all $\pi_i$'s are taken
equal to a single value $\pi$.

%\input{Navarre.tex}


\subsection{Brain cancer in Navarre (Spain)}

\citet{Ugarteetal:2006} analyse the incidence of brain cancer in Navarre
(Spain). The aggregation level is the health district. Figure~\ref{fig:Navarre}
shows the Standardised Mortality Ratios. As it can be seen there are many areas
where the SMR is zero because there are no cases in those areas.
\citet{Ugarteetal:2004} also assessed a significant zero-inflation of these
data compared to a Poisson distribution. For cluster detection, the method
implemented in \code{DClusterm} is similar to the one used in \citet{RD:2010}
for the detection of disease clusters of rare diseases.


<<echo=FALSE, results=hide>>=
library(DClusterm)
library(snowfall)
library(pscl)

data(Navarre)
@


\begin{figure}[!h]
<<echo=FALSE, fig=TRUE>>=
print(spplot(brainnav, "SMR", cuts = 8, 
  col.regions = brewer.pal(9, "Oranges")))
@
\caption{SMR of brain cancer in Navarre (Spain).}
\label{fig:Navarre}
\end{figure}


\subsection{Cluster detection}

%\subsubsection{Cluster detection with no covariates}

Before starting our cluster detection methods, we will check the
appropriateness of a Poisson distribution for this data. Fitting a log-linear
model (with no covariates) gives the following model:

<<>>=
nav.m0 <- glm(OBSERVED ~ offset(log(EXPECTED)) + 1, family = "poisson", data = brainnav)

summary(nav.m0)
@

Furthermore, a quasipoisson model has been fit in order to asses any
extra-variation in the data:

<<>>=
nav.m0q <- glm(OBSERVED ~ offset(log(EXPECTED)) + 1, family = "quasipoisson", 
   data = brainnav)
summary(nav.m0q)
@
\noindent
The dispersion parameter in the previous model seems to be higher than 1,
which may mean that the Poisson distribution is not appropriate.

For this reason, and following \citet{Ugarteetal:2004}, a zero-inflated Poisson
model has been fit using function \code{zeroinfl()} from package \pkg{pscl}.
Here is the resulting model:


<<>>=
nav.m0zip <- zeroinfl(OBSERVED ~ offset(log(EXPECTED)) + 1 | 1, data = brainnav,
  dist = "poisson", x = TRUE)
summary(nav.m0zip)
@

Hence, the zero-inflated Poisson model will be used now to detect clusters
of disease. As in the example on the New York leukemia dataset, a \pkg{spacetime}
object will store all the information. The column for the expected counts must
be names \code{Expected}, and this is our first step now. Note also that,
because only one time period is considered, data will have a single value and
it is the 1st of January of 1990.

<<>>=
brainnav$Expected <- brainnav$EXPECTED

brainnavst <- STFDF(as(brainnav, "SpatialPolygons"),
  xts(1,as.Date("1990-01-01")), as(brainnav, "data.frame"),
  endTime = as.POSIXct(strptime(c("1990-01-01"), "%Y-%m-%d"), tz = "GMT"))
@

Function \code{DetectClustersModel()} will perform the cluster detection using
a \code{zeroinfl} model. This provides a very flexible way of handling different
types of models in \proglang{R} for cluster detection.

<<results = hide>>=
cl0 <- DetectClustersModel(brainnavst, coordinates(brainnav), fractpop = 0.25, 
   alpha = 0.05, typeCluster = "S", R = NULL, numCPUS = 4, model0 = nav.m0zip)
@

The output will show the following clusters:

<<>>=   
cl0
@
\noindent
As it can be seen, two clusters (with a p-value lower than 0.05) are detected.
However, they overlap and we will just consider the one with the lowest
p-value, which is shown in Figure~\ref{fig:Navarrecl}.

An index for the areas in each of the detected cluster can be obtained with
function \code{knbinary()}. This function will return a \code{data.frame} with
all the dummy cluster variables, i.e., the \code{data.frame} will have as many
columns as clusters and a number of rows equal to the number of areas. Entries
will be 1 if an areas is in a given cluster and 0 otherwise. This indices can
be used for a number of analyses, such as checking whether two clusters overlap
or computing the number of times an area is included in a cluster. In the
follwing example we obtain the representation of all the clusters detected and
the first one, the most significant, is added as a new column to the original
\code{SpatialPolygonsDataFrame} to be displayed in Figure~\ref{fig:Navarrecl}.

<<>>=
nav.clusters <- knbinary(brainnav, cl0)
brainnav$CLUSTER <- as.factor(nav.clusters[, 1]) 
levels(brainnav$CLUSTER) <- c("", "CLUSTER")
@

\begin{figure}[!h]
\centering
<<fig=TRUE, echo=FALSE>>=
print(spplot(brainnav, "CLUSTER", col.regions = c("white", "grey")) )
@
\caption{Cluster of brain cancer detected in Navarre (Spain).}
\label{fig:Navarrecl}
\end{figure}


\section{Mixed-effects models for cluster detection}
\label{sec:mixed}


\section{Bivariate models for cluster detection}
\label{sec:bivar}


\section{Discussion}
\label{sec:disc}




\bibliography{DClusterm}
%\bibliographystyle{chicago}




\end{document}
